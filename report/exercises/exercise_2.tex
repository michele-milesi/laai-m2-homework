\section*{Exercise 2}

\subsection*{Exercise 1.35}
Show that the golden ratio $ \varphi $ is a fixed point of the transformation $ x \mapsto 1 + \frac{1}{x} $, and use this fact
to compute $ \varphi $ by means of the \texttt{fixed-point} procedure.

\begin{lstlisting}
(define tolerance 0.00001)

(define (fixed-point f first-guess)
  (define (close-enough? v1 v2)
    (< (abs (- v1 v2))
       tolerance))
  (define (try guess)
    (let ((next (f guess)))
      (if (close-enough? guess next)
          next
          (try next))))
  (try first-guess))
\end{lstlisting}

\paragraph{Solution}
The \textit{golden ratio} is defined as follows: \[ \varphi = \frac{1 + \sqrt{5}}{2} \approx 1.618 \]
It is the fixed point of the transformation $ x \mapsto 1 + \frac{1}{x} $ indeed if we apply the transformation to $ \varphi $
we obtain:
\[ 
    1 + \frac{1}{\varphi} = 1 + \cfrac{1}{\cfrac{1 + \sqrt{5}}{2}} = 1 + \frac{2}{1 + \sqrt{5}} = \frac{3 + \sqrt{5}}{1 + \sqrt{5}} 
    = \frac{3 + \sqrt{5}}{1 + \sqrt{5}} \cdot \frac{1 - \sqrt{5}}{1 - \sqrt{5}} = \frac{-2 - 2\sqrt{5}}{-4} =
    \frac{1 + \sqrt{5}}{2} = \varphi
\]

The transformation can be defined in Racket as follows:
\begin{lstlisting}
; definition of transformation x -> 1 + 1/x
(define (transformation x)
  (+ 1 (/ 1 x)))

; definition of golden ratio
(define phi (/ (+ 1 (sqrt 5)) 2))
\end{lstlisting}
And the procedure \texttt{fixed-point} is used to compute the \textit{golden ratio}, as shown below, we can observe that the procedure
\texttt{fixed-point} computes $ \varphi $ with a good level of approximation.
\begin{lstlisting}
> (fixed-point transformation 1.1)
1.6180364726455159
> phi
1.618033988749895
\end{lstlisting}

\subsection*{Exercise 1.36}
Modify \texttt{fixed-point} so that it prints the sequence of approximations it generates, using the \texttt{newline} and 
\texttt{display} primitives shown in Exercise 1.22. Then find a solution to $ x^{x} = 1000 $ by finding a fixed point of
$ x \mapsto \frac{\log(1000)}{\log(x)} $.
(Use Scheme's primitive \texttt{log} procedure, which computes natural logarithms).
Compare the number of steps this takes with and without average damping.
(Note that you cannot start \texttt{fixed-point} with a guess of $ 1 $, as this would cause division by $ \log(1) = 0 $).

\paragraph{Solution} First of all the procedure \texttt{fixed-point} has been modified in order to print the sequence of 
approximations it generates.
\begin{lstlisting}[caption={Procedure \texttt{fixed-point} which prints the sequence of approximations it generates},captionpos=b]
(define (fixed-point-print-seq f first-guess)
  (define (close-enough? v1 v2)
    (< (abs (- v1 v2))
       tolerance))
  (define (try guess)
    (display guess)
    (newline)
    (let ((next (f guess)))
      (if (close-enough? guess next)
          next
          (try next))))
  (try first-guess))
\end{lstlisting}
Then the transformation $ x \mapsto \frac{\log(1000)}{\log(x)} $ has been defined in racket as follows 
(both with and without average damping):
\begin{lstlisting}[caption={Transformation without average-damping},captionpos=b]
(define (log-transformation x)
  (/ (log 1000) (log x)))
\end{lstlisting}
\begin{lstlisting}[caption={Transformation with average damping},captionpos=b]
; definition of procedure which computes the average
(define (average x y) 
  (/ (+ x y) 2))

; definition of transformation x -> log(1000) / log(x) 
;with average damping
(define (log-transformation-avg-dmp)
  (fixed-point-print-seq
   (lambda (x)
     (average x (log-transformation x)))
   1.1))
\end{lstlisting}
After that the two procedures are used to make a comparison between the number of steps, in both cases the initial guess is $ 1.1 $
and it can be  show how the procedure with average damping takes less time to converge to the solution.
Below the approximation of the two methods are shown, the approximation without average damping takes $ 37 $ steps, while 
the approximation with average damping takes $ 13 $ steps.
\begin{lstlisting}
; without average damping       ; with average damping
> (fixed-point-print-seq        > (log-transformation-avg-dmp)       
    log-transformation 1.1)          
1.1                             1.1
72.47657378429035               36.78828689214517
1.6127318474109593              19.352175531882512
14.45350138636525               10.84183367957568
2.5862669415385087              6.870048352141772
7.269672273367045               5.227224961967156
3.4822383620848467              4.701960195159289
5.536500810236703               4.582196773201124
4.036406406288111               4.560134229703681
4.95053682041456                4.5563204194309606
4.318707390180805               4.555669361784037
4.721778787145103               4.555558462975639
4.450341068884912               4.55553957996306
4.626821434106115               4.555536364911781
4.509360945293209
4.586349500915509
4.535372639594589
4.568901484845316
4.546751100777536
4.561341971741742
4.551712230641226
4.558059671677587
4.55387226495538
4.556633177654167
4.554812144696459
4.556012967736543
4.555220997683307
4.555743265552239
4.555398830243649
4.555625974816275
4.555476175432173
4.555574964557791
4.555509814636753
4.555552779647764
4.555524444961165
4.555543131130589
4.555530807938518
4.555538934848503
\end{lstlisting} 

\subsection*{Exercise 1.37}
\begin{itemize}
    \item[a.] An infinite \textit{continued fraction} is an expression of the form 
        \[ f = \cfrac{N_{1}}{D_{1} + \cfrac{N_{2}}{D_{2} + \cfrac{N_{3}}{D_{3} + \dots}}} \] 
        As an example, one can show that the infinite continued fraction expansion with the $ N_{i} $ and the $ D_{i} $
        all equal to $ 1 $ produces $ \cfrac{1}{\varphi} $, where $ \varphi $ is the golden ratio.
        One way to approximate an infinite continued fraction is to truncate the expansion after a given number of terms.
        Such a truncation $ - $ a so-called \textit{k-term finite continued fraction} $ - $ has the form
        \[ \cfrac{N_{1}}{D_{1} + \cfrac{N_{2}}{\ddots + \cfrac{N_{k}}{D_{k}}}} \]
        Suppose that \texttt{n} and \texttt{d} are procedures of one argument (the term index $ i $) that return the $ N_{i} $
        and $ D_{i} $ of the terms of the continued fraction.
        Define a procedure \texttt{cont-frac} such that evaluating \texttt{(cont-frac n d k)} computes the value of the $k$-term
        finite continued fraction. Check your procedure by approximating $ \frac{1}{\varphi} $ using
        \begin{lstlisting}
(cont-frac (lambda (i) 1.0)
           (lambda (i) 1.0)
           k)
        \end{lstlisting} 
        for succesive values ok \texttt{k}. How large must you make \texttt{k} in order to get an approximation that is accurate
        to 4 decimals places?
    
    \item[b.] If your \texttt{cont-frac} procedure generates a recursive process, write one that generates an iterative process. If
        it generates an iterative process, write one that generates a recursive process.    
\end{itemize}

\paragraph{Solution}
\begin{itemize}
    \item[a.] The procedure \texttt{cont-frac} has been defined with a recursive process. The function has 3 parameters: \textit{(i)}
        \texttt{n} which is the function that returns the element $ N_{i} $ of the continued fraction; \textit{(ii)} \texttt{d}
        which is the function that returns the element $ D_{i} $ of the continued fraction; \textit{(iii)} \texttt{k} which is the
        number of iterations to be performed.
        In the body of the function is defined the local recursive procedure \texttt{cont-frac-rec} which is responsable for
        computing recursivly the continued fraction. It has two formal parameters: \texttt{k} and \texttt{counter} which is the 
        counter of the performed iterations; when the \texttt{counter} reaches \texttt{k} (i.e. the number of iterations to be
        performed) the base case is reached and the returned value is computed.
        The procedure \texttt{cont-frac} calls the procedure \texttt{cont-frac-rec} with initial parameters \texttt{k} and $ 0 $,
        in this way we are sure that the number of iterations performed will be k (with \texttt{counter} from $1$ to \texttt{k}).
        The code is shown below:
\begin{lstlisting}[caption={Recursive procedure \texttt{cont-frac}},captionpos=b]
(define (cont-frac n d k)
  (define (cont-frac-rec k counter) 
    (if (= counter k)
        (/ (n counter) (d counter))
        (/ (n counter)
           (+ (d counter) 
              (cont-frac-rec k (+ counter 1))))))
  (cont-frac-rec k 1))
\end{lstlisting}
        Then it has been tested by approximating $ 1 / \varphi \sim 0.6180 $. When $ k = 11 $ or grater, the approximation is
        accurate to 4 decimals places.
    \item[b.] Since before the procedure generates a recursive process, it has been rewritten in order to generate an iterative
        process.
\begin{lstlisting}
(define (cont-frac-iter n d k res)
  (if (= k 0)
      (/ (n k) res)
      (cont-frac-iter n 
                      d 
                      (- k 1) 
                      (+ (d (- k 1)) 
                         (/ (n k) res)))))
\end{lstlisting}   
\end{itemize}


\subsection*{Exercise 1.38}
In 1737, the Swiss mathematician Leonhard Euler published a memoir \textit{De Fractionibus Continuis}, which
included a continued fraction expansion for $ e - 2 $, where $ e $ is the base of the natural logarithms.
In this fraction, the $ N_{i} $ are all $ 1 $, and the $ D_{i} $ are successively $ 1, 2, 1, 1, 4, 1, 1, 6, 1, 1, 8, \dots $.
Write a program that uses your \texttt{cont-frac} procedure from Exercise 1.37 to approximate $ e $, based on Euler's expansion.

\paragraph{Solution}